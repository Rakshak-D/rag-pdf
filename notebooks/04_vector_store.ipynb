{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Vector store",
   "id": "ad45c77e16c3b0e9"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-29T06:08:24.973213700Z",
     "start_time": "2026-01-29T06:08:23.674001300Z"
    }
   },
   "source": [
    "import json # Used for receiving image object or document while creating a hash id .\n",
    "from typing import List,Dict,Union # For datatype of a variable .\n",
    "import chromadb # Used for creating a vectorDB .\n",
    "import os # For getting directory path for storing vector database .\n",
    "import hashlib # Used for creating hashid for documents\n",
    "import numpy as np\n",
    "from langchain_core.documents import Document"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T06:08:24.988781100Z",
     "start_time": "2026-01-29T06:08:24.974212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The following function is used to create hashid using content of a document of image object .\n",
    "def stable_hash(obj:dict|str)->str:\n",
    "    if isinstance(obj,dict):\n",
    "        obj=json.dumps(obj,sort_keys=True,ensure_ascii=False)\n",
    "\n",
    "    return hashlib.sha256(obj.encode(\"utf-8\")).hexdigest()"
   ],
   "id": "8e2fcc19e7168893",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T06:08:25.046049600Z",
     "start_time": "2026-01-29T06:08:24.990171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Used for initializing vectorDB and also store data in collection .\n",
    "class VectorStore:\n",
    "    def __init__(self,collection_name:str,directory:str=\"../data/database\"):\n",
    "        self.collection_name=collection_name # Collection name .\n",
    "        self.persistent_directory=directory # Directory to store database .\n",
    "        self.collection=None # Collection , used to store data .\n",
    "        self.client=None # Used to connect database .\n",
    "        self.initialize_store() # Initializing vectordb .\n",
    "\n",
    "    def initialize_store(self):\n",
    "            try:\n",
    "                os.makedirs(name=self.persistent_directory,exist_ok=True) # Checking if directory exists ,if not creating one .\n",
    "                self.client=chromadb.PersistentClient(path=self.persistent_directory)\n",
    "\n",
    "                if self.collection_exists(self.collection_name): # Checking if the collection exists , if collection exists then loading it ..\n",
    "                    print(f\"Loading collection {self.collection_name} from database .\")\n",
    "                    self.collection=self.client.get_collection(self.collection_name)\n",
    "\n",
    "                else: # If collection does not exist then creating it .\n",
    "                    print(f\"New collection {self.collection_name} created in database .\")\n",
    "                    self.collection=self.client.create_collection(self.collection_name)\n",
    "\n",
    "                print(f\"Vector store initialized .\") # Success message is vector store initialized .\n",
    "                print(f\"Existing documents in collection {self.collection.count()}\")\n",
    "\n",
    "            except Exception as e: # Exception handling .\n",
    "                raise RuntimeError(\"Could not initialize vector store .\") from e\n",
    "\n",
    "    # The following function is used to add data and its embedding to a collection .\n",
    "    def add_documents(self,documents:List[Union[Dict,Document]],embeddings:np.ndarray):\n",
    "        if not self.collection: # Checking if collection is initialized .\n",
    "            raise RuntimeError(\"Collection is not initialized .\")\n",
    "\n",
    "        if len(documents)!=len(embeddings): # Checking if number of documents and embeddings are same .\n",
    "            raise ValueError(\"Number of documents does not match embeddings .\") # If not raise an error\n",
    "\n",
    "        ids,metadatas,texts=[],[],[] # Used to store main content and metadata .\n",
    "\n",
    "        for doc in documents:\n",
    "            if isinstance(doc,Document): # For text embeddings . Document type .\n",
    "                content=doc.page_content.strip()\n",
    "                metadata=doc.metadata or {}\n",
    "\n",
    "                hash_input={ # Data used for creating hashid .\n",
    "                    \"content\":content,\n",
    "                    \"source\":metadata.get(\"source\"),\n",
    "                    \"page\":metadata.get(\"page_num\")\n",
    "                }\n",
    "                doc_id=stable_hash(hash_input)\n",
    "                texts.append(content) # Appending data to store it in vectorDB\n",
    "                metadatas.append(metadata)\n",
    "\n",
    "            elif isinstance(doc,dict): # For image embeddings . Dict type .\n",
    "                hash_input={ # Data used for creating hashid .\n",
    "                    \"image_path\":doc.get(\"image_path\"),\n",
    "                    \"bbox\":doc.get(\"bbox\"),\n",
    "                    \"caption\":doc.get(\"caption_text\",\"\")\n",
    "                }\n",
    "\n",
    "                doc_id=stable_hash(hash_input)\n",
    "                texts.append(doc.get(\"caption_text\",\"\")) # Appending data to store it in vectorDB\n",
    "                metadatas.append(doc)\n",
    "\n",
    "            else:\n",
    "                raise TypeError(f\"Unsupported document type :{type(doc)}\") # If the input neither Document or Dict .\n",
    "\n",
    "            ids.append(doc_id)\n",
    "\n",
    "        existing_ids=set( # Used to check if the document is previously added .\n",
    "            self.collection.get(include=[])[\"ids\"]\n",
    "        )\n",
    "\n",
    "        new_indices=[ # Appending new documents by checking data through hashid .\n",
    "            i for i ,doc_id in enumerate(ids)\n",
    "            if doc_id not in existing_ids\n",
    "        ]\n",
    "\n",
    "        if not new_indices: # Checking if there are new documents to add to collection .\n",
    "            print(\"No new documents to add\")\n",
    "            return\n",
    "\n",
    "        self.collection.add( # Adding new documents to collection\n",
    "            ids=[ids[i] for i in new_indices],\n",
    "            documents=[texts[i] for i in new_indices],\n",
    "            metadatas=[metadatas[i] for i in new_indices],\n",
    "            embeddings=[embeddings[i].tolist() for i in new_indices]\n",
    "        )\n",
    "        print(f\"Added {len(new_indices)} new documents to collection .\")\n",
    "    # The following function is used to check if the collection exists .\n",
    "    def collection_exists(self,collection_name:str)->bool:\n",
    "        collection_in_db=self.client.list_collections()\n",
    "        return any(col.name==collection_name for col in collection_in_db )"
   ],
   "id": "94afc45f193bb886",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T06:08:25.379104300Z",
     "start_time": "2026-01-29T06:08:25.048052200Z"
    }
   },
   "cell_type": "code",
   "source": "vector_store=VectorStore(collection_name=\"test_collection\")",
   "id": "a71972d053186bdd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New collection test_collection created in database .\n",
      "Vector store initialized .\n",
      "Existing documents in collection 0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T06:08:37.035886400Z",
     "start_time": "2026-01-29T06:08:25.381097300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Libraries used for creating test sample .\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from langchain_core.documents import Document\n",
    "from sentence_transformers import SentenceTransformer"
   ],
   "id": "b90558a691d314a7",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T06:08:37.179589300Z",
     "start_time": "2026-01-29T06:08:37.163063400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Used to create test embeddings .\n",
    "def embed_documents_minilm(documents: List[Document]) -> np.ndarray:\n",
    "    if not documents:\n",
    "        raise ValueError(\"No documents provided\")\n",
    "\n",
    "    texts = [doc.page_content.strip() for doc in documents]\n",
    "\n",
    "    model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "    embeddings = model.encode(\n",
    "        texts,\n",
    "        normalize_embeddings=True,\n",
    "        convert_to_numpy=True,\n",
    "        batch_size=32\n",
    "    )\n",
    "\n",
    "    return embeddings"
   ],
   "id": "990c7d80fe2ec84e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T06:08:37.228400Z",
     "start_time": "2026-01-29T06:08:37.181118800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test data .\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"The Hubble Space Telescope changed astronomy.\",\n",
    "        metadata={\"source\": \"hubble.pdf\", \"page_num\": 1}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Black holes bend spacetime.\",\n",
    "        metadata={\"source\": \"physics.pdf\", \"page_num\": 3}\n",
    "    )\n",
    "]"
   ],
   "id": "5ca4b15e284edc75",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T06:08:44.798643Z",
     "start_time": "2026-01-29T06:08:37.232399100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embeddings = embed_documents_minilm(docs) # Creating test data embeddings\n",
    "\n",
    "vector_store.add_documents(docs, embeddings) # Adding documents to collection ."
   ],
   "id": "1a9449c2b801dbfe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 2 new documents to collection .\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T06:08:44.904858200Z",
     "start_time": "2026-01-29T06:08:44.828611700Z"
    }
   },
   "cell_type": "code",
   "source": "vector_store.__init__(\"test_collection\") # Checking if the documents are inserted .",
   "id": "6a8a791efc309420",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading collection test_collection from database .\n",
      "Vector store initialized .\n",
      "Existing documents in collection 2\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T06:08:57.238773700Z",
     "start_time": "2026-01-29T06:08:57.179088200Z"
    }
   },
   "cell_type": "code",
   "source": "vector_store.add_documents(docs, embeddings) # Adding same documents to collection .",
   "id": "22f327ca9f43c167",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new documents to add\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
