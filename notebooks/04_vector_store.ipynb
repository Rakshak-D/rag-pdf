{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Vector store",
   "id": "ad45c77e16c3b0e9"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-29T09:29:20.693855400Z",
     "start_time": "2026-01-29T09:29:19.991466100Z"
    }
   },
   "source": [
    "import json # Used for receiving image object or document while creating a hash id .\n",
    "from typing import List,Dict,Union # For datatype of a variable .\n",
    "import chromadb # Used for creating a vectorDB .\n",
    "import os # For getting directory path for storing vector database .\n",
    "import hashlib # Used for creating hashid for documents\n",
    "import numpy as np\n",
    "from langchain_core.documents import Document"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T09:29:20.726057100Z",
     "start_time": "2026-01-29T09:29:20.701080100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The following function is used to create hashid using content of a document of image object .\n",
    "def stable_hash(obj:dict|str)->str:\n",
    "    if isinstance(obj,dict):\n",
    "        obj=json.dumps(obj,sort_keys=True,ensure_ascii=False)\n",
    "\n",
    "    return hashlib.sha256(obj.encode(\"utf-8\")).hexdigest()"
   ],
   "id": "8e2fcc19e7168893",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T09:29:20.763053600Z",
     "start_time": "2026-01-29T09:29:20.728057300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The following function is used to remove None type and replace it with empty string since chromadb cannot store type None .\n",
    "def sanitize_metadata(metadata: dict) -> dict:\n",
    "    clean = {}\n",
    "    for k, v in metadata.items():\n",
    "        if v is None:\n",
    "            clean[k] = \"\" # None -> Empty string\n",
    "        elif isinstance(v, (str, int, float, bool)):\n",
    "            clean[k] = v # Keep it as it is .\n",
    "        else:\n",
    "            clean[k] = str(v) # Convert unknown type to string .\n",
    "    return clean # Return sanitized metadata .\n"
   ],
   "id": "87f0b93e97a73bf7",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T09:29:20.802054Z",
     "start_time": "2026-01-29T09:29:20.780055100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Used for initializing vectorDB and also store data in collection .\n",
    "class VectorStore:\n",
    "    def __init__(self,collection_name:str,directory:str=\"../data/database\"):\n",
    "        self.collection_name=collection_name # Collection name .\n",
    "        self.persistent_directory=directory # Directory to store database .\n",
    "        self.collection=None # Collection , used to store data .\n",
    "        self.client=None # Used to connect database .\n",
    "        self.initialize_store() # Initializing vectordb .\n",
    "\n",
    "    def initialize_store(self):\n",
    "            try:\n",
    "                os.makedirs(name=self.persistent_directory,exist_ok=True) # Checking if directory exists ,if not creating one .\n",
    "                self.client=chromadb.PersistentClient(path=self.persistent_directory)\n",
    "\n",
    "                if self.collection_exists(self.collection_name): # Checking if the collection exists , if collection exists then loading it ..\n",
    "                    print(f\"Loading collection {self.collection_name} from database .\")\n",
    "                    self.collection=self.client.get_collection(self.collection_name)\n",
    "\n",
    "                else: # If collection does not exist then creating it .\n",
    "                    print(f\"New collection {self.collection_name} created in database .\")\n",
    "                    self.collection=self.client.create_collection(self.collection_name)\n",
    "\n",
    "                print(f\"Vector store initialized .\") # Success message is vector store initialized .\n",
    "                print(f\"Existing documents in collection {self.collection.count()}\")\n",
    "\n",
    "            except Exception as e: # Exception handling .\n",
    "                raise RuntimeError(\"Could not initialize vector store .\") from e\n",
    "\n",
    "    # The following function is used to add data and its embedding to a collection .\n",
    "    def add_documents(self,documents:List[Union[Dict,Document]],embeddings:np.ndarray):\n",
    "        if not self.collection: # Checking if collection is initialized .\n",
    "            raise RuntimeError(\"Collection is not initialized .\")\n",
    "\n",
    "        if len(documents)!=len(embeddings): # Checking if number of documents and embeddings are same .\n",
    "            raise ValueError(\"Number of documents does not match embeddings .\") # If not raise an error\n",
    "\n",
    "        ids,metadatas,texts=[],[],[] # Used to store main content and metadata .\n",
    "\n",
    "        for doc in documents:\n",
    "            if isinstance(doc,Document): # For text embeddings . Document type .\n",
    "                content=doc.page_content.strip()\n",
    "                metadata=doc.metadata or {}\n",
    "\n",
    "                metadata=sanitize_metadata(metadata)\n",
    "                hash_input={ # Data used for creating hashid .\n",
    "                    \"content\":content,\n",
    "                    \"source\":metadata.get(\"source\"),\n",
    "                    \"page\":metadata.get(\"page_num\",\"\")\n",
    "                }\n",
    "                doc_id=stable_hash(hash_input)\n",
    "                texts.append(content) # Appending data to store it in vectorDB\n",
    "                metadatas.append(metadata)\n",
    "\n",
    "            elif isinstance(doc,dict): # For image embeddings . Dict type .\n",
    "                bbox = doc.get(\"bbox\")\n",
    "                image_metadata = {\n",
    "                \"image_path\": doc.get(\"path\", \"\"),\n",
    "                \"caption_text\": doc.get(\"caption_text\", \"\"),\n",
    "                \"bbox\": json.dumps(bbox) if bbox is not None else \"\",\n",
    "                }\n",
    "\n",
    "                image_metadata = sanitize_metadata(image_metadata) # Removing None or unknown datatype .\n",
    "\n",
    "                hash_input = { # Used for hashid .\n",
    "                \"image_path\": image_metadata[\"image_path\"],\n",
    "                \"bbox\": image_metadata[\"bbox\"],\n",
    "                \"caption\": image_metadata[\"caption_text\"],\n",
    "                }\n",
    "\n",
    "                doc_id=stable_hash(hash_input)\n",
    "                texts.append(doc.get(\"caption_text\",\"\")) # Appending data to store it in vectorDB\n",
    "                metadatas.append(image_metadata)\n",
    "\n",
    "            else:\n",
    "                raise TypeError(f\"Unsupported document type :{type(doc)}\") # If the input neither Document or Dict .\n",
    "\n",
    "            ids.append(doc_id)\n",
    "\n",
    "        existing_ids=set( # Used to check if the document is previously added .\n",
    "            self.collection.get(include=[])[\"ids\"]\n",
    "        )\n",
    "\n",
    "        seen=set()\n",
    "        new_indices=[]\n",
    "\n",
    "        for i, doc_id in enumerate(ids):\n",
    "            if doc_id in existing_ids:\n",
    "                continue\n",
    "            if doc_id in seen:\n",
    "                continue\n",
    "            seen.add(doc_id)\n",
    "            new_indices.append(i)\n",
    "\n",
    "        if not new_indices: # Checking if there are new documents to add to collection .\n",
    "            print(\"No new documents to add\")\n",
    "            return\n",
    "\n",
    "        self.collection.add( # Adding new documents to collection\n",
    "            ids=[ids[i] for i in new_indices],\n",
    "            documents=[texts[i] for i in new_indices],\n",
    "            metadatas=[metadatas[i] for i in new_indices],\n",
    "            embeddings=[embeddings[i].tolist() for i in new_indices]\n",
    "        )\n",
    "        print(f\"Added {len(new_indices)} new documents to collection .\")\n",
    "    # The following function is used to check if the collection exists .\n",
    "    def collection_exists(self,collection_name:str)->bool:\n",
    "        collection_in_db=self.client.list_collections()\n",
    "        return any(col.name==collection_name for col in collection_in_db )"
   ],
   "id": "c66172e7d618c5f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T09:29:21.010528200Z",
     "start_time": "2026-01-29T09:29:20.804052200Z"
    }
   },
   "cell_type": "code",
   "source": "vector_store=VectorStore(collection_name=\"test_collection\")",
   "id": "297a01e51b59659b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New collection test_collection created in database .\n",
      "Vector store initialized .\n",
      "Existing documents in collection 0\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T09:29:28.672651500Z",
     "start_time": "2026-01-29T09:29:21.012526100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Libraries used for creating test sample .\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from langchain_core.documents import Document\n",
    "from sentence_transformers import SentenceTransformer"
   ],
   "id": "ecf7bc0f8965d830",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T09:29:28.806578100Z",
     "start_time": "2026-01-29T09:29:28.746964500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Used to create test embeddings .\n",
    "def embed_documents_minilm(documents: List[Document]) -> np.ndarray:\n",
    "    if not documents:\n",
    "        raise ValueError(\"No documents provided\")\n",
    "\n",
    "    texts = [doc.page_content.strip() for doc in documents]\n",
    "\n",
    "    model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "    embeddings = model.encode(\n",
    "        texts,\n",
    "        normalize_embeddings=True,\n",
    "        convert_to_numpy=True,\n",
    "        batch_size=32\n",
    "    )\n",
    "\n",
    "    return embeddings"
   ],
   "id": "75a6cdc89c3d7021",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T09:29:28.841579300Z",
     "start_time": "2026-01-29T09:29:28.819578300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test data .\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"The Hubble Space Telescope changed astronomy.\",\n",
    "        metadata={\"source\": \"hubble.pdf\", \"page_num\": 1}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Black holes bend spacetime.\",\n",
    "        metadata={\"source\": \"physics.pdf\", \"page_num\": 3}\n",
    "    )\n",
    "]"
   ],
   "id": "de34242b69eeffad",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T09:29:37.483370800Z",
     "start_time": "2026-01-29T09:29:28.843581100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embeddings = embed_documents_minilm(docs) # Creating test data embeddings\n",
    "\n",
    "vector_store.add_documents(docs, embeddings) # Adding documents to collection ."
   ],
   "id": "dfb6767891e8095d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 2 new documents to collection .\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T09:29:37.565329300Z",
     "start_time": "2026-01-29T09:29:37.499596700Z"
    }
   },
   "cell_type": "code",
   "source": "vector_store.__init__(\"test_collection\") # Checking if the documents are inserted .",
   "id": "d027255a64ca25dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading collection test_collection from database .\n",
      "Vector store initialized .\n",
      "Existing documents in collection 2\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T09:29:37.614366800Z",
     "start_time": "2026-01-29T09:29:37.566335600Z"
    }
   },
   "cell_type": "code",
   "source": "vector_store.add_documents(docs, embeddings) # Adding same documents to collection .",
   "id": "8fc481b5c8ef0f23",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new documents to add\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
