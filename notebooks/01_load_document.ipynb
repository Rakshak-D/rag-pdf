{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-24T18:13:19.551447800Z",
     "start_time": "2026-01-24T18:13:13.475855200Z"
    }
   },
   "source": [
    "#Libraries used\n",
    "from unstructured.partition.pdf import partition_pdf # For conversion of PDF into elements .\n",
    "from langchain_core.documents import Document # For converting elements into Document .\n",
    "from pathlib import Path # For Loading the directory or PDF path .\n",
    "from typing import List\n",
    "import traceback # Used for error handling ."
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T18:13:19.565768500Z",
     "start_time": "2026-01-24T18:13:19.552420500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to load all the PDF's from Directory .\n",
    "def loading_pdf(dir_path:str='../data/pdf')->List[Document]: # Return type .\n",
    "    dir_path=Path(dir_path) # Loading directory Path\n",
    "\n",
    "    if not dir_path.is_dir(): # Checking if the directory is valid .\n",
    "        raise NotADirectoryError(f\"{dir_path} is a invalid directory .\")\n",
    "\n",
    "    print(f\"The directory path is : {dir_path} .\")\n",
    "    docs=list(dir_path.rglob(\"*.pdf\")) # Storing all the PDF's path into list .\n",
    "    print(f\"Number of PDF's in directory is {len(docs)}\")\n",
    "\n",
    "    if len(docs)==0: # Checking if any PDFs exists in the directory .\n",
    "        print('No documents in the dir_path')\n",
    "        return []\n",
    "\n",
    "    # All these variables used for stats check at the end .\n",
    "    all_pdf_size=0.0\n",
    "    all_elements=[]\n",
    "    all_documents=[]\n",
    "    failed_pdf=[]\n",
    "\n",
    "    print(\"=\"*20,\"PDF LOAD SUMMARY\",\"=\"*20)\n",
    "    print(\"-\"*45)\n",
    "\n",
    "    for serial,pdf_path in enumerate(docs): # Iterating through all the PDFs in directory .\n",
    "        print(f\"{serial+1} ---> Loading {pdf_path.name} \")\n",
    "        pdf_size_bytes=pdf_path.stat().st_size\n",
    "        pdf_size_mb=pdf_size_bytes/(1024**2) # Calculating size of the PDF .\n",
    "        print(f\"File size : {pdf_size_mb:.3f} MB\")\n",
    "        try:\n",
    "            imag_dir= Path('../data/images') / pdf_path.stem # Directory for storing images in the PDF .\n",
    "            imag_dir.mkdir(parents=True,exist_ok=True)\n",
    "            # This function automatically detects the layout, detect texts , extract images and other required content in the PDF .\n",
    "            # filename -> Name or path of the PDF .\n",
    "            # extract_images_in_pdf -> Used to extract images in PDF and store it in given Directory or default stores in base64 and stores in metadata and also if extract_images_in_pdf works only is strategy is True .\n",
    "            # infer_table_structure -> Used for better table structure and this works if strategy is hi_res.\n",
    "            # strategy -> This is used for layout detection . Note - Different strategy techniques also requires different cpu computation time .\n",
    "            # image_output_dir_path -> Used for redirecting images into a directory or file .\n",
    "            # languages -> Used to specify the language the PDF is written.\n",
    "            # Note - The following function requires Poppler (for PDF rendering) and Tesseract (for image based pdf for converting text into actual text ,since in image based PDF no texts can be extracted .)\n",
    "            # Links to download\n",
    "            # -> https://github.com/oschwartz10612/poppler-windows\n",
    "            # -> https://github.com/tesseract-ocr/tesseract\n",
    "            pdf=partition_pdf(\n",
    "                              filename=str(pdf_path),\n",
    "                              extract_images_in_pdf=True,\n",
    "                              infer_table_structure=True,\n",
    "                              strategy='hi_res',\n",
    "                              image_output_dir_path=imag_dir, # Fix this issue the image is not storing in intended directory .\n",
    "                              languages=['eng']\n",
    "                              )\n",
    "\n",
    "            for element in pdf:\n",
    "            # Used to convert the elements containing text into Documents and also remove the elements with minimum texts .\n",
    "                if element.text and len(element.text.strip())>20:\n",
    "                    all_documents.append(\n",
    "                        Document(\n",
    "                            page_content=element.text,\n",
    "                            # Adding metadata .\n",
    "                            metadata={\n",
    "                                **element.metadata.to_dict() # Expands the dictionary into new one .\n",
    "                                }\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "            print(f\"Total Elements in the PDF : {len(pdf)}\") # Printing elements in a single pdf .\n",
    "            all_pdf_size+=pdf_size_mb\n",
    "            all_elements.extend(pdf) # Storing elements of PDF .\n",
    "            print(\"-\"*45)\n",
    "        except Exception as e:\n",
    "            print(f\" Error loading {pdf_path.name} . Error {e}\") # Exception handling .\n",
    "            failed_pdf.append(pdf_path.name) # Storing the PDF failed to load .\n",
    "            traceback.print_exc() # Used to trace failures similar to python interpreter stack trace .\n",
    "\n",
    "    # Some stats of Loading all the PDF in a directory .\n",
    "    print(f\"Total size of all the PDF's are : {all_pdf_size:.3f} MB\")\n",
    "    print(f\"Total Elements from all the PDF's : {len(all_elements)}\")\n",
    "    print(f\"Total Number of Documents : {len(all_documents)} \")\n",
    "    print(\"-\"*45)\n",
    "\n",
    "    # Printing all the PDF which where not able to load .\n",
    "    if failed_pdf:\n",
    "        print(f\"Failed PDF : {failed_pdf}\")\n",
    "\n",
    "    return all_documents # Returning the loaded Documents . Type -> List of Document"
   ],
   "id": "1d90f767eec62068",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T18:17:10.939180400Z",
     "start_time": "2026-01-24T18:13:19.566767900Z"
    }
   },
   "cell_type": "code",
   "source": "documents=loading_pdf() # Loading PDF",
   "id": "f2cb373838247046",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory path is : ..\\data\\pdf .\n",
      "Number of PDF's in directory is 1\n",
      "==================== PDF LOAD SUMMARY ====================\n",
      "---------------------------------------------\n",
      "1 ---> Loading hubble-science-highlights.pdf \n",
      "File size : 14.789 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Elements in the PDF : 746\n",
      "---------------------------------------------\n",
      "Total size of all the PDF's are : 14.789 MB\n",
      "Total Elements from all the PDF's : 746\n",
      "Total Number of Documents : 410 \n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T18:17:11.067755600Z",
     "start_time": "2026-01-24T18:17:11.021026700Z"
    }
   },
   "cell_type": "code",
   "source": "print(documents[0]) # First Document of the extracted PDF elements .",
   "id": "f76294da8c3ddd4f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Reshaping Our Cosmic View Hubble Science Highlights' metadata={'detection_class_prob': 0.35657215118408203, 'is_extracted': 'true', 'coordinates': {'points': ((np.float64(524.7530517578125), np.float64(1336.1209716796875)), (np.float64(524.7530517578125), np.float64(1678.66552734375)), (np.float64(1399.0055555555552), np.float64(1678.66552734375)), (np.float64(1399.0055555555552), np.float64(1336.1209716796875))), 'system': 'PixelSpace', 'layout_width': 1700, 'layout_height': 2200}, 'last_modified': '2026-01-22T23:26:37', 'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'file_directory': '..\\\\data\\\\pdf', 'filename': 'hubble-science-highlights.pdf'}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T18:17:11.095755Z",
     "start_time": "2026-01-24T18:17:11.068755600Z"
    }
   },
   "cell_type": "code",
   "source": "print(documents[0].type) # Type of the data",
   "id": "5294901989690860",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T18:17:11.133755100Z",
     "start_time": "2026-01-24T18:17:11.097757500Z"
    }
   },
   "cell_type": "code",
   "source": "print(documents[0].page_content) # Page content or basically text",
   "id": "ee95a12d281fc237",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping Our Cosmic View Hubble Science Highlights\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-24T18:17:11.152758100Z",
     "start_time": "2026-01-24T18:17:11.135756200Z"
    }
   },
   "cell_type": "code",
   "source": "print(documents[0].metadata) # Metadata of a Document",
   "id": "bf449b83b7ad4543",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'detection_class_prob': 0.35657215118408203, 'is_extracted': 'true', 'coordinates': {'points': ((np.float64(524.7530517578125), np.float64(1336.1209716796875)), (np.float64(524.7530517578125), np.float64(1678.66552734375)), (np.float64(1399.0055555555552), np.float64(1678.66552734375)), (np.float64(1399.0055555555552), np.float64(1336.1209716796875))), 'system': 'PixelSpace', 'layout_width': 1700, 'layout_height': 2200}, 'last_modified': '2026-01-22T23:26:37', 'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'file_directory': '..\\\\data\\\\pdf', 'filename': 'hubble-science-highlights.pdf'}\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
